============================= 
파트 1 : 자, 시작합시다 
============================= 

소개 
-------- 

몇몇 분들이 얼마전에 `Twisted <http://twistedmatrix.com/>`_ 의 `메일링리스트
<http://twistedmatrix.com/cgi-bin/mailman/listinfo/twisted-python>`_ 에
"마감시간을 앞둔 사람들을 위한 Twisted 소개" 같은 글을 부탁하는 `게시물
<http://twistedmatrix.com/pipermail/twisted-python/2009-May/019706.html>`_ 을
올렸습니다.  사실을 말하자면, 이건 그런 글은 아닙니다. Twisted와 Python에서의
비동기 프로그래밍 입문용 문서라는 면에서는 정반대일지도 모릅니다.  이 문서는
시간이 없거나 끈기가 없는 분들에게 적합한 입문용 문서가 아닙니다.

아무튼, 당신이 비동기 프로그래밍의 초심자라면 -- 적어도 당신이 천재가 아니라면
-- 빠른 입문용 문서라는 것은 아무튼 무리일 것이라고 생각합니다.

나는 몇 년간 Twisted를 잘 사용해오면서, 내가 초반에 어떻게 (천천히) 학습했고,
어떤 점이 어려웠는지 생각해보다가, 중요한 점은 Twisted를 다루는 법이 아니라
비동기적인 코드를 작성하고 이해할 수 있는 "정신 모델"을 획득하는 것이 중요하다는
결론에 도달했습니다.

대부분의 프리 소프트웨어들을 보면, Twisted 소스 코드의 대부분은 명확하고 잘
작성되어있으며 온라인으로 읽을 수있는 문서도 훌륭합니다.  그러나 정신 모델이
없으면 Twisted 소스 코드와 Twisted를 사용하는 코드나 대량의 문서를 읽어도
혼란스럽고 머리만 아플 것입니다.

따라서이 입문의 첫 번째 파트에서는 독자가 모델을 이해하기 쉽도록하고, Twisted
기능 소개는 그 이후에 진행할 것입니다.  사실 처음에는 Twisted을 전혀 사용하지
않고, 대신에 어떻게 비동기 시스템이 작동하는 방법을 설명하기위한 간단한 Python
프로그램을 사용합니다.
그리고 Twisted를 사용하게되면 일상적인 프로그래밍에서 일반적으로 사용하지 않는
것이다 낮은 관점에서 시작할 것입니다.  Twisted는 고도로 추상화된 시스템이고,
문제를 해결할 때 굉장한 지렛대 역할을 해줍니다.
그러나 Twisted을 배우고 있거나 Twisted가 실제로 어떻게 작동하는지 이해하려고 할
때는 많은 추상화된 부분은 문제가 됩니다.  그러므로 안쪽에서 바깥쪽으로 기본적인
것부터 이야기를 진행시켜 나갑시다.

일단 멘탈 모델을 획득하면 `Twisted 문서
<http://twistedmatrix.com/trac/wiki/Documentation>`_ 를 읽고 `소스 코드
<http://twistedmatrix.com/trac/browser>`_ 를 살펴보는 것은 훨씬 쉽게 느껴질
것이라 생각합니다.  시작합시다.

모델 
------

동기화 모델과의 차이를 명확하게하기 위해 (바라건대) 친숙한 두 개의 모델에서
시작합시다.  그림처럼 프로그램을 완료하기 위해 꼭 실행해야하는 개념적으로
독립적인 세 개의 작업으로 구성된 프로그램을 상상해 봅시다.  이 작업들은 나중에
구체화하겠지만 지금은 프로그램이 그것들을 작동시켜야 한다는 것을 제외하고는
다른 점은 언급하지 않습니다.  나아가 "작업"이라는 단어를 "실행될 필요가있는
무엇"라는 비 기술적인 개념에서 사용하고있는 점에 유의하십시오.

첫 번째 모델은 친숙한 단일 스레드 동기화 모델입니다. 아래의 그림1을 보세요. 

.. _figure1 : 

.. figure :: images / p01_sync.png 

그림1: 동기화 모델 


이것은 프로그래밍에서 가장 간단한 형태입니다.  각각의 작업은 한 번에 하나씩
밖에 실행되지 않고 다른 작업이 시작되기 전에있는 작업은 완전히 종료합니다.
작업이 항상 정해진 순서대로 실행된다면 나중에 실행되는 작업의 구현은 사전에
수행되는 모든 작업이 오류없이 종료하고 그 출력을 사용할 수 있는 상황이라 가정할
수 있습니다.  논리적으로 매우 단순합니다.

동기화 모델과 대조적인 것들로 그림2 스레드 모델을들 수 있습니다. 

.. _figure2 : 

.. figure :: images / p01_threaded.png 

그림2: 스레딩 모델 

이 모델에서는 각각의 작업은 별도의 쓰레드 제어 하에서 실행됩니다.  스레드는
OS에 의해 관리되고 여러 프로세서 및 코어를 가지는 시스템에서는 진정한 병렬로,
단일 프로세서 시스템에서는 인터리브 방식으로 동시 실행됩니다.  중요한 점은,
스레드 모델에서 실행의 자세한 내용은 OS에 의해 제어되기 때문에, 프로그래머는
단순히 일련의 명령이 동시에 실행될 수 있다는 점을 고려해서 생각하면 된다는
점입니다.


다이어그램은 간단하지만 스레드가 서로 협조해야하므로 실제 스레드 프로그래밍은
매우 복잡하게 될 수 있습니다.  스레드 간 통신 및 스레드의 협조는 프로그래밍의
고급 기법이며, 제대로 사용하는 것은 어렵습니다.

여러 스레드 대신 여러 프로세스를 사용하여 평행을 구현하는 프로그램도 있습니다.
프로그래밍의 자세한 내용은 다르지만 우리의 목적에서 보면 그림 2에 표시된 것과
같은 모델입니다.

드디어 그림3에서 비동기 모델을 소개합니다.

.. _figure3:

.. figure:: images/p01_async.png

그림3: 비동기 모델 

이 모델에서, 작업은 다른 작업과  인터리브된  단일 스레드로 제어됩니다.
프로그래머는 하나의 작업이 실행되는 중에는 다른 작업이 실행되지 않다는 점을
알고 있기 때문에 스레드의 경우보다 간단합니다.  단일 프로세서 시스템에서는
스레드 프로그램도 마찬가지로 작동하지만 여러 프로세서 시스템에 이식 할 때
프로그램이 잘못 작동하지 않도록 스레드를 사용하는 프로그래머는 그림 3 대신 그림
2의 관점에서 생각해야 입니다.  그러나 단일 스레드 비동기 시스템은 멀티 프로세서
시스템에서도 항상 인터리브로 실행되는 것입니다.

비동기와 스레드 모델은 또 다른 차이점이 있습니다.  스레드 시스템에서 스레드를
일시 정지시켜 다른 스레드를 실행하는 결정은 프로그래머가 제어할 수 있는 일이
아닙니다.  그것은 운영 체제의 일이고, 프로그래머는 거의 모든 경우에서 스레드는
일시 중지되고 다른 스레드로 대체될 수 있다고 생각하지 않으면 안됩니다.  이에
반해 비동기 모델에서는, 작업은 명시적으로 다른 작업에게 제어를 양보할 때까지
계속 실행될 것입니다.  이것은 스레드의 경우에 비해 매우 단순합니다.

동일한 시스템에서 비동기와 스레드의 두 모델을 혼합하거나 함께 사용할 수도
있다는 점에 유의하십시오. 그러나 이 문서의 대부분은 단일 스레드 제어에서 비동기
시스템만을 취급합니다.

동기 
----

비동기 모델은 단일 명령 처리 흐름밖에 없고 작업이 언제든지 중단될 수 있는 것이
아니라 명시적으로 제어를 양보하는 것이기 때문에 스레드 모델보다 단순하다는 것을
지금까지 보아왔습니다.  그러나 비동기 모델은 동기 모델보다 분명히 복잡합니다.
프로그래머가 각각의 작업을 간헐적으로 수행될 수 있는 더욱 작은 단계의 흐름으로
구성해야하기 때문입니다.  그리고 만약 하나의 작업이 다른 작업의 출력을 사용하고
있다면, 그 의존적인 작업은 모든 것을 정리해 놓은 것 말고 일련의 조각이나 부분을
입력받아 처리할수 있도록 코드를 작성해야 합니다.  실제로 비동기 모델에서는
작업이 동시에 진행되지 않으므로 비동기 프로그램은 동기 프로그램만큼 수행시간이
걸릴 수도 있고 어쩌면 비동기 프로그램이 더 빈약한 `참조 지역성
<http://en.wikipedia.org/wiki/Locality_of_reference>`_ 을 드러내는 만큼 더 오래
걸릴 수도 있습니다.


그럼, 왜 비동기 모델을 선택할까요?  여기에는 적어도 두 가지 이유가 있습니다.
첫째, 하나 또는 그 이상의 작업이 인간 상호 작용을 맡고 있으면 작업을 인터리브
방식으로 처리함으로써 시스템은 다른 작업을 "백그라운드"에서 작동시키면서
사용자의 입력을 기다릴 수 있습니다.  시스템이 백그라운드 작업을 빠르게 수행하지
못할지도 모르지만, 사용하는 인간에게는 더욱 쾌적할 것입니다.

그러나 비동기 시스템이 동기 시스템보다 간단하게 잘 작동하려면 극적으로 모든 개별
작업들이 전체적으로 더욱 짧은 시간동안 실행되어야 한다는 조건이 있습니다.

그림4에서 나타난 예처럼 작업들이 서로 기다리게 하거나, 서로를 차단할 때 그렇지
못합니다.

.. _figure4 : 

.. figure :: images / p01_block.png 

그림4 : 동기화 프로그래밍 차단 

이 그림에서 회색 부분은 특정 작업이 기다리고 있어서 (차단되어서) 진척이 없는
기간을 나타냅니다. 왜 작업이 차단되는 걸까요? 가장 자주 발생하는 이유는
입출력(I/O) 조작이나 외부 기기에 대한 데이터 전송을 기다리는 것입니다.  전형적인
CPU는 디스크나 네트워크에서 사용할 수 있는 것에 대해 비교가 되지 않을 정도로
빠른 속도로 데이터를 전송할 수 있습니다.  즉, 많은 입출력을 수반하는 동기화
프로그램은 디스크나 네트워크가 따라 잡을 때까지 많은 시간을 차단하게 될
것입니다. 이러한 동기화 프로그램은 그 이유로 차단 프로그램(blocking
program)이라고도합니다. 

그림4에서 보듯이 차단 프로그램이 그림3의 비동기 프로그램과 비슷하게 보이는 것에
주목하십시오. 우연의 일치가 아닙니다. 비동기 모델의 기본적인 아이디어는
비동기적으로 실행되는 프로그램 -- 동기적인 프로그램에서 차단되는 작업에 직면했을
때 대신에 진행할 수 있는 다른 작업을 실행하는 것입니다.  그래서 비동기적
프로그램은 어떤 작업도 진행할 수 없을 때에만 차단(block)되므로
논블로킹(non-blocking) 프로그램이라고도 합니다.  또한 하나의 작업에서 다른
작업으로의 전환은 첫번째 작업이 종료되거나 그 작업이 차단해야 하는 상황에
이르렀는지 중 하나에 대응합니다.  잠재적으로 대량의 블로킹 작업이 있으면 대강
개별 작업에 소요되는 실제 시간은 같은 정도이지만 전체적으로 대기 시간이 짧아지기
때문에 비동기 프로그램은 동기 프로그램에 비해 크게 성능을 향상시킬 수 있습니다. 

동기화 모델과 비교하여 비동기 모델이 성능을 발휘하는 것은 다음과 같은
경우입니다. 

대량의 작업이 있어서, 거의 항상 그중  적어도 하나는 진행될 때.   작업이 대량의
입출력을 처리해서, 동기 프로그램이 다른 작업이 실행될 수도 있는 시간을 낭비하는
상황을 유발할 때.  작업이 서로 독립적이어서 작업 간의 통신이 거의 필요 없을 때.
(따라서, 하나의 작업이 다른 작업을 기다릴 필요 없음) 이러한 조건은
클라이언트-서버 환경의 고부하 네트워크 서버(웹서버 등)와 거의 완전하게
일치합니다.

각각의 작업은 요청 수신과 응답 전송이라는 형태로 입출력을 수반하는 클라이언트
요청 처리입니다.

그리고 클라이언트의 요청(대부분이 읽기)는 대개 독립적입니다.  따라서 네트워크
서버의 구현은 비동기 모델에 가장 적합한 후보이고, 이것이 바로 Twisted가 가장
적합한 네트워크 라이브러리인 이유입니다.


다음은 ------ 

이제 파트 1은 끝입니다.  ":doc:`p02`"에서는 약간의 차단 방식 및 비차단 방식
네트워크 프로그램을 작성하면서, (Twisted를 사용하지 않고) 최대한 쉽게 Python으로
비동기 프로그램을 어떻게 작성하는지 감을 잡아볼 것입니다.



..
    <H2>Part 1: In Which We Begin at the Beginning
    <H3>Preface
    Someone recently <A href="http://twistedmatrix.com/pipermail/twisted-python/2009-May/019706.html">posted</A> to the <A href="http://twistedmatrix.com/">Twisted</A> <A href="http://twistedmatrix.com/cgi-bin/mailman/listinfo/twisted-python">mailing list</A> asking for something like the "Twisted introduction for people on a deadline". Full disclosure: this isn't it. On the spectrum of introductions to Twisted and asynchronous programming in Python, it may be on the exact opposite end. So if you don't have any time, or any patience, this isn't the introduction you are looking for.
    However, I also believe that if you are new to asynchronous programming, a quick introduction is simply not possible, at least if you are not a genius. I've used Twisted successfully for a number of years and having thought about how I initially learned it (slowly), and what I found difficult, I've come to the conclusion that much of the challenge does not stem from Twisted per se, but rather in the acquisition of the "mental model" required to write and understand asynchronous code. Most of the Twisted source code is clear and well written, and the online documentation is good, at least by the standards of most free software. But without that mental model, reading the Twisted codebase, or code that uses Twisted, or even much of the documentation, will result in confusion and headache.
    So the first parts of this introduction are designed to help you acquire that model and only later on will we introduce the features of Twisted. In fact, we will start without using Twisted at all, instead using simple Python programs to illustrate how an asynchronous system works. And once we get into Twisted, we will begin with very low-level aspects that you would not normally use in day-to-day programming. Twisted is a highly abstracted system and this gives you tremendous leverage when you use it to solve problems. But when you are learning Twisted, and particularly when you are trying to understand how Twisted actually works, the many levels of abstraction can cause troubles. So we will go from the inside-out, starting with the basics.
    And once you have the mental model in place, I think you will find reading the <A href="http://twistedmatrix.com/trac/wiki/Documentation">Twisted documentation</A>, or just <A href="http://twistedmatrix.com/trac/browser">browsing the source code</A>, to be much easier. So let's begin.
    <H3>The Models
    We will start by reviewing two (hopefully) familiar models in order to contrast them with the asynchronous model. By way of illustration we will imagine a program that consists of three conceptually distinct tasks which must be performed to complete the program. We will make these tasks more concrete later on, but for now we won't say anything about them except the program must perform them. Note I am using "task" in the non-technical sense of "something that needs to be done".
    The first model we will look at is the familiar single-threaded synchronous model, in Figure 1 below:<A name="figure1"></A>
    <DIV id="attachment_2026" class="wp-caption aligncenter" style="width: 146px"><A href="./part1_files/sync.png"><IMG class="size-full wp-image-2026" title="Figure 1: the synchronous model" src="./part1_files/sync.png" alt="Figure 1: the synchronous model" width="136" height="361"></A><P class="wp-caption-text">Figure 1: the synchronous model</DIV>
    This is the simplest style of programming. Each task is perfomed one at a time, with one finishing completely before another is started. And if the tasks are always performed in a definite order, the implementation of a later task can assume that all earlier tasks have finished without errors, with all their output available for use&nbsp;— a definite simplification in logic.
    We can contrast the synchronous model with another one, the threaded model illustrated in Figure 2:
    <DIV id="attachment_2028" class="wp-caption aligncenter" style="width: 388px"><A href="./part1_files/threaded.png"><IMG class="size-full wp-image-2028" title="Figure 2: the threaded model" src="./part1_files/threaded.png" alt="Figure 2: the threaded model" width="378" height="120"></A><P class="wp-caption-text">Figure 2: the threaded model</DIV>
    In this model, each task is performed in a separate thread of control. The threads are managed by the operating system and may, on a system with multiple processors or multiple cores, run truly concurrently, or may be interleaved together on a single processor. The point is, in the threaded model the details of execution are handled by the OS and the programmer simply thinks in terms of independent instruction streams which may run simultaneously. Although the diagram is simple, in practice threaded programs can be quite complex because of the need for threads to coordinate with one another. Thread communication and coordination is an advanced programming topic and can be difficult to get right.
    Some programs implement parallelism using multiple processes instead of multiple threads. Although the programming details are different, for our purposes it is the same model as in Figure 2.
    Now we can introduce the asynchronous model in Figure 3:<A name="figure3"></A>
    <DIV id="attachment_2030" class="wp-caption aligncenter" style="width: 186px"><A href="./part1_files/async.png"><IMG class="size-full wp-image-2030" title="Figure 3: the asynchronous model" src="./part1_files/async.png" alt="Figure 3: the asynchronous model" width="176" height="361"></A><P class="wp-caption-text">Figure 3: the asynchronous model</DIV>
    In this model, the tasks are interleaved with one another, but in a single thread of control. This is simpler than the threaded case because the programmer always knows that when one task is executing, another task is not. Although in a single-processor system a threaded program will also execute in an interleaved pattern, a programmer using threads should still think in terms of Figure 2, not Figure 3, lest the program work incorrectly when moved to a multi-processor system. But a single-threaded asynchronous system will always execute with interleaving, even on a multi-processor system.
    There is another difference between the asynchronous and threaded models. In a threaded system the decision to suspend one thread and execute another is largely outside of the programmer's control. Rather, it is under the control of the operating system, and the programmer must assume that a thread may be suspended and replaced with another at almost any time. In contrast, under the asynchronous model a task will continue to run until it explicitly relinquishes control to other tasks. This is a further simplification from the threaded case.
    <P style="padding-left: 30px;">Note that it is possible to mix the asynchronous and threaded models and use both in the same system. But for most of this introduction, we will stick to "plain vanilla" asynchronous systems with one thread of control.
    <H3>The Motivation
    We've seen that the asynchronous model is simpler than the threaded one because there is a single instruction stream and tasks explicitly relinquish control instead of being suspended arbitrarily. But the asynchronous model is clearly more complex than the synchronous case. The programmer must organize each task as a sequence of smaller steps that execute intermittently. And if one task uses the output of another, the dependent task must be written to accept its input as a series of bits and pieces instead of all together. Since there is no actual parallelism, it appears from our diagrams that an asynchronous program will take just as long to execute as a synchronous one, perhaps longer as the asynchronous program might exhibit poorer <A href="http://en.wikipedia.org/wiki/Locality_of_reference">locality of reference</A>.
    So why would you choose to use the asynchronous model? There are at least two reasons. First, if one or more of the tasks are responsible for implementing an interface for a human being, then by interleaving the tasks together the system can remain responsive to user input while still performing other work in the "background". So while the background tasks may not execute any faster, the system will be more pleasant for the person using it.
    However, there is a condition under which an asynchronous system will simply outperform a synchronous one, sometimes dramatically so, in the sense of performing all of its tasks in an overall shorter time. This condition holds when tasks are forced to wait, or <EM>block</EM>, as illustrated in Figure 4:<A name="figure4"></A>
    <DIV id="attachment_2032" class="wp-caption aligncenter" style="width: 267px"><A href="./part1_files/block.png"><IMG class="size-full wp-image-2032" title="Figure 4: blocking in a synchronous program" src="./part1_files/block.png" alt="Figure 4: blocking in a synchronous program" width="257" height="361"></A><P class="wp-caption-text">Figure 4: blocking in a synchronous program</DIV>
    In the figure, the gray sections represent periods of time when a particular task is waiting (blocking) and thus cannot make any progress. Why would a task be blocked? The most typical reason is that it is waiting to perform I/O, to transfer data to or from an external device. A typical CPU can handle data transfer rates that are orders of magnitude faster than a disk or a network link is capable of sustaining. Thus, a synchronous program that is doing lots of I/O will spend much of its time blocked while a disk or network catches up. Such a synchronous program is also called a blocking program for that reason.
    Notice that Figure 4, a blocking program, looks a bit like Figure 3, an asynchronous program. This is not a coincidence. The fundamental idea behind the asynchronous model is that an asynchronous program, when faced with a task that would normally block in a synchronous program, will instead execute some other task that can still make progress. So an asynchronous program only "blocks" when no task can make progress and is thus called a non-blocking program. And each switch from one task to another corresponds to the first task either finishing, or coming to a point where it would have to block. With a large number of potentially blocking tasks, an asynchronous program can outperform a synchronous one by spending less overall time waiting, while devoting a roughly equal amount of time to real work on the individual tasks.
    Compared to the synchronous model, the asynchronous model performs best when:
    <OL>
    * There are a large number of tasks so there is likely always at least one task that can make progress.
    * The tasks perform lots of I/O, causing a synchronous program to waste lots of time blocking when other tasks could be running.
    * The tasks are largely independent from one another so there is little need for inter-task communication (and thus for one task to wait upon another).
    </OL>
    These conditions almost perfectly characterize a typical busy network server (like a web server) in a client-server environment. Each task represents one client request with I/O in the form of receiving the request and sending the reply. And client requests (being mostly reads) are largely independent. So a network server implementation is a prime candidate for the asynchronous model and this is why Twisted is first and foremost a networking library.
    <H3>Onward and Upward
    This is the end of Part 1. In <A href="http://krondo.com/blog/?p=1247">Part 2</A>, we will write some network programs, both blocking and non-blocking, as simply as possible (without using Twisted), to get a feel for how an asynchronous Python program actually works.
